# VQ-GAN Configuration for Patch-Wise Distributed Training
# Optimized for single H200 GPU with 144GB memory

name: VQGAN_PATCHES
seed: 1234
batch_size: 1  # Process 1 volume at a time (~24 patches)
num_workers: 4  # Reduced to avoid memory issues

# Single GPU settings
gpus: 1
accumulate_grad_batches: 1  # Must be 1 for manual optimization

# Training
default_root_dir: ./outputs/vqgan_patches_distributed/
max_epochs: 30
learning_rate: 1e-4
precision: 16  # Use mixed precision to reduce memory usage
# Note: gradient_clip_val handled manually in model (automatic_optimization=False)

# Model Architecture (from baseline)
embedding_dim: 64
n_codes: 512
n_hiddens: 64

# Downsampling (same as baseline - applied to patches)
downsample: [4, 4, 4]

# Discriminator (disabled initially)
disc_channels: 64
disc_layers: 3
discriminator_iter_start: 100000  # Very high to disable
disc_loss_type: hinge

# Loss weights
image_gan_weight: 0.0
video_gan_weight: 0.0
l1_weight: 1.0
gan_feat_weight: 0.0
perceptual_weight: 0.0

# Codebook
restart_thres: 1.0
no_random_restart: false

# Architecture details
norm_type: group
padding_type: constant
num_groups: 32

# Distributed training specific
find_unused_parameters: false
sync_batchnorm: true

# Expected memory usage per GPU:
# - Model: ~500 MB
# - Batch (2 patches × 256×256×128): ~64 MB
# - Activations + Gradients: ~40 GB
# - Total: ~41 GB / 144 GB = 28% utilization
